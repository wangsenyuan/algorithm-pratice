You are given two arrays ğ‘
 and ğ‘
, each contains ğ‘›
 integers.

You want to create a new array ğ‘
 as follows: choose some real (i.e. not necessarily integer) number ğ‘‘
, and then for every ğ‘–âˆˆ[1,ğ‘›]
 let ğ‘ğ‘–:=ğ‘‘â‹…ğ‘ğ‘–+ğ‘ğ‘–
.

Your goal is to maximize the number of zeroes in array ğ‘
. What is the largest possible answer, if you choose ğ‘‘
 optimally?

 ### ideas
 1. c = d * a + b = 0
 2. d * a = -b
 3. d = - (b / a)
 4. å¦‚æœa = 0ï¼Œ é‚£ä¹ˆè¦æ±‚b = 0
 5. å¦‚æœb = 0, è¦ä¹ˆè¦æ±‚ a * d = 0
 6. å¦‚æœa != 0, b != 0, é‚£ä¹ˆè¦æ±‚ d * a = -b